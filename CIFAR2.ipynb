{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "#data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 59  62  63]\n",
      "   [ 43  46  45]\n",
      "   [ 50  48  43]\n",
      "   ...\n",
      "   [158 132 108]\n",
      "   [152 125 102]\n",
      "   [148 124 103]]\n",
      "\n",
      "  [[ 16  20  20]\n",
      "   [  0   0   0]\n",
      "   [ 18   8   0]\n",
      "   ...\n",
      "   [123  88  55]\n",
      "   [119  83  50]\n",
      "   [122  87  57]]\n",
      "\n",
      "  [[ 25  24  21]\n",
      "   [ 16   7   0]\n",
      "   [ 49  27   8]\n",
      "   ...\n",
      "   [118  84  50]\n",
      "   [120  84  50]\n",
      "   [109  73  42]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[208 170  96]\n",
      "   [201 153  34]\n",
      "   [198 161  26]\n",
      "   ...\n",
      "   [160 133  70]\n",
      "   [ 56  31   7]\n",
      "   [ 53  34  20]]\n",
      "\n",
      "  [[180 139  96]\n",
      "   [173 123  42]\n",
      "   [186 144  30]\n",
      "   ...\n",
      "   [184 148  94]\n",
      "   [ 97  62  34]\n",
      "   [ 83  53  34]]\n",
      "\n",
      "  [[177 144 116]\n",
      "   [168 129  94]\n",
      "   [179 142  87]\n",
      "   ...\n",
      "   [216 184 140]\n",
      "   [151 118  84]\n",
      "   [123  92  72]]]\n",
      "\n",
      "\n",
      " [[[154 177 187]\n",
      "   [126 137 136]\n",
      "   [105 104  95]\n",
      "   ...\n",
      "   [ 91  95  71]\n",
      "   [ 87  90  71]\n",
      "   [ 79  81  70]]\n",
      "\n",
      "  [[140 160 169]\n",
      "   [145 153 154]\n",
      "   [125 125 118]\n",
      "   ...\n",
      "   [ 96  99  78]\n",
      "   [ 77  80  62]\n",
      "   [ 71  73  61]]\n",
      "\n",
      "  [[140 155 164]\n",
      "   [139 146 149]\n",
      "   [115 115 112]\n",
      "   ...\n",
      "   [ 79  82  64]\n",
      "   [ 68  70  55]\n",
      "   [ 67  69  55]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[175 167 166]\n",
      "   [156 154 160]\n",
      "   [154 160 170]\n",
      "   ...\n",
      "   [ 42  34  36]\n",
      "   [ 61  53  57]\n",
      "   [ 93  83  91]]\n",
      "\n",
      "  [[165 154 128]\n",
      "   [156 152 130]\n",
      "   [159 161 142]\n",
      "   ...\n",
      "   [103  93  96]\n",
      "   [123 114 120]\n",
      "   [131 121 131]]\n",
      "\n",
      "  [[163 148 120]\n",
      "   [158 148 122]\n",
      "   [163 156 133]\n",
      "   ...\n",
      "   [143 133 139]\n",
      "   [143 134 142]\n",
      "   [143 133 144]]]\n",
      "\n",
      "\n",
      " [[[255 255 255]\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   ...\n",
      "   [253 253 253]\n",
      "   [253 253 253]\n",
      "   [253 253 253]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   ...\n",
      "   [255 255 255]\n",
      "   [255 255 255]\n",
      "   [255 255 255]]\n",
      "\n",
      "  [[255 255 255]\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   ...\n",
      "   [254 254 254]\n",
      "   [254 254 254]\n",
      "   [254 254 254]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[113 120 112]\n",
      "   [111 118 111]\n",
      "   [105 112 106]\n",
      "   ...\n",
      "   [ 72  81  80]\n",
      "   [ 72  80  79]\n",
      "   [ 72  80  79]]\n",
      "\n",
      "  [[111 118 110]\n",
      "   [104 111 104]\n",
      "   [ 99 106  98]\n",
      "   ...\n",
      "   [ 68  75  73]\n",
      "   [ 70  76  75]\n",
      "   [ 78  84  82]]\n",
      "\n",
      "  [[106 113 105]\n",
      "   [ 99 106  98]\n",
      "   [ 95 102  94]\n",
      "   ...\n",
      "   [ 78  85  83]\n",
      "   [ 79  85  83]\n",
      "   [ 80  86  84]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 35 178 235]\n",
      "   [ 40 176 239]\n",
      "   [ 42 176 241]\n",
      "   ...\n",
      "   [ 99 177 219]\n",
      "   [ 79 147 197]\n",
      "   [ 89 148 189]]\n",
      "\n",
      "  [[ 57 182 234]\n",
      "   [ 44 184 250]\n",
      "   [ 50 183 240]\n",
      "   ...\n",
      "   [156 182 200]\n",
      "   [141 177 206]\n",
      "   [116 149 175]]\n",
      "\n",
      "  [[ 98 197 237]\n",
      "   [ 64 189 252]\n",
      "   [ 69 192 245]\n",
      "   ...\n",
      "   [188 195 206]\n",
      "   [119 135 147]\n",
      "   [ 61  79  90]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 73  79  77]\n",
      "   [ 53  63  68]\n",
      "   [ 54  68  80]\n",
      "   ...\n",
      "   [ 17  40  64]\n",
      "   [ 21  36  51]\n",
      "   [ 33  48  49]]\n",
      "\n",
      "  [[ 61  68  75]\n",
      "   [ 55  70  86]\n",
      "   [ 57  79 103]\n",
      "   ...\n",
      "   [ 24  48  72]\n",
      "   [ 17  35  53]\n",
      "   [  7  23  32]]\n",
      "\n",
      "  [[ 44  56  73]\n",
      "   [ 46  66  88]\n",
      "   [ 49  77 105]\n",
      "   ...\n",
      "   [ 27  52  77]\n",
      "   [ 21  43  66]\n",
      "   [ 12  31  50]]]\n",
      "\n",
      "\n",
      " [[[189 211 240]\n",
      "   [186 208 236]\n",
      "   [185 207 235]\n",
      "   ...\n",
      "   [175 195 224]\n",
      "   [172 194 222]\n",
      "   [169 194 220]]\n",
      "\n",
      "  [[194 210 239]\n",
      "   [191 207 236]\n",
      "   [190 206 235]\n",
      "   ...\n",
      "   [173 192 220]\n",
      "   [171 191 218]\n",
      "   [167 190 216]]\n",
      "\n",
      "  [[208 219 244]\n",
      "   [205 216 240]\n",
      "   [204 215 239]\n",
      "   ...\n",
      "   [175 191 217]\n",
      "   [172 190 216]\n",
      "   [169 191 215]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[207 199 181]\n",
      "   [203 195 175]\n",
      "   [203 196 173]\n",
      "   ...\n",
      "   [135 132 127]\n",
      "   [162 158 150]\n",
      "   [168 163 151]]\n",
      "\n",
      "  [[198 190 170]\n",
      "   [189 181 159]\n",
      "   [180 172 147]\n",
      "   ...\n",
      "   [178 171 160]\n",
      "   [175 169 156]\n",
      "   [175 169 154]]\n",
      "\n",
      "  [[198 189 173]\n",
      "   [189 181 162]\n",
      "   [178 170 149]\n",
      "   ...\n",
      "   [195 184 169]\n",
      "   [196 189 171]\n",
      "   [195 190 171]]]\n",
      "\n",
      "\n",
      " [[[229 229 239]\n",
      "   [236 237 247]\n",
      "   [234 236 247]\n",
      "   ...\n",
      "   [217 219 233]\n",
      "   [221 223 234]\n",
      "   [222 223 233]]\n",
      "\n",
      "  [[222 221 229]\n",
      "   [239 239 249]\n",
      "   [233 234 246]\n",
      "   ...\n",
      "   [223 223 236]\n",
      "   [227 228 238]\n",
      "   [210 211 220]]\n",
      "\n",
      "  [[213 206 211]\n",
      "   [234 232 239]\n",
      "   [231 233 244]\n",
      "   ...\n",
      "   [220 220 232]\n",
      "   [220 219 232]\n",
      "   [202 203 215]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[150 143 135]\n",
      "   [140 135 127]\n",
      "   [132 127 120]\n",
      "   ...\n",
      "   [224 222 218]\n",
      "   [230 228 225]\n",
      "   [241 241 238]]\n",
      "\n",
      "  [[137 132 126]\n",
      "   [130 127 120]\n",
      "   [125 121 115]\n",
      "   ...\n",
      "   [181 180 178]\n",
      "   [202 201 198]\n",
      "   [212 211 207]]\n",
      "\n",
      "  [[122 119 114]\n",
      "   [118 116 110]\n",
      "   [120 116 111]\n",
      "   ...\n",
      "   [179 177 173]\n",
      "   [164 164 162]\n",
      "   [163 163 161]]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[300],interpolation='nearest')\n",
    "y_train[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Richard\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = RMSprop(lr=0.0001)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "10016/50000 [=====>........................] - ETA: 3:00 - loss: 2.1701 - acc: 0.1877"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-02317d6763cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m               shuffle=True)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "#model.add(Conv2D(32, (3, 3), padding='same',\n",
    "#                 input_shape=x_train.shape[1:]))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(32, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(64, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(100))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(num_classes))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 12s 234us/sample - loss: 2.0717 - acc: 0.2394 - val_loss: 1.8950 - val_acc: 0.3248\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 13s 268us/sample - loss: 1.9297 - acc: 0.3037 - val_loss: 1.8026 - val_acc: 0.3726\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 13s 258us/sample - loss: 1.8752 - acc: 0.3305 - val_loss: 1.7539 - val_acc: 0.3953\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 1.8408 - acc: 0.3429 - val_loss: 1.7047 - val_acc: 0.4030\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 11s 225us/sample - loss: 1.8182 - acc: 0.3507 - val_loss: 1.7164 - val_acc: 0.4019\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 11s 224us/sample - loss: 1.7982 - acc: 0.3624 - val_loss: 1.6676 - val_acc: 0.4147\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 12s 242us/sample - loss: 1.7798 - acc: 0.3682 - val_loss: 1.6894 - val_acc: 0.4013\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.7646 - acc: 0.3732 - val_loss: 1.6469 - val_acc: 0.4206\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 16s 318us/sample - loss: 1.7506 - acc: 0.3780 - val_loss: 1.6290 - val_acc: 0.4311\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 12s 246us/sample - loss: 1.7418 - acc: 0.3841 - val_loss: 1.6306 - val_acc: 0.4296\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 11s 224us/sample - loss: 1.7324 - acc: 0.3841 - val_loss: 1.6109 - val_acc: 0.4389\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 12s 237us/sample - loss: 1.7238 - acc: 0.3917 - val_loss: 1.5945 - val_acc: 0.4432\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 12s 243us/sample - loss: 1.7181 - acc: 0.3928 - val_loss: 1.6034 - val_acc: 0.4332\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 12s 246us/sample - loss: 1.7090 - acc: 0.3946 - val_loss: 1.6345 - val_acc: 0.4188\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 12s 244us/sample - loss: 1.7021 - acc: 0.3950 - val_loss: 1.5925 - val_acc: 0.4404\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 12s 245us/sample - loss: 1.6961 - acc: 0.3975 - val_loss: 1.5855 - val_acc: 0.4404\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 12s 246us/sample - loss: 1.6905 - acc: 0.4018 - val_loss: 1.5960 - val_acc: 0.4376\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 12s 247us/sample - loss: 1.6870 - acc: 0.4042 - val_loss: 1.5647 - val_acc: 0.4537\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 12s 233us/sample - loss: 1.6807 - acc: 0.4056 - val_loss: 1.5919 - val_acc: 0.4506\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 12s 237us/sample - loss: 1.6717 - acc: 0.4086 - val_loss: 1.5810 - val_acc: 0.4405\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 12s 232us/sample - loss: 1.6730 - acc: 0.4054 - val_loss: 1.5512 - val_acc: 0.4526\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 12s 241us/sample - loss: 1.6717 - acc: 0.4066 - val_loss: 1.5368 - val_acc: 0.4618\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 12s 231us/sample - loss: 1.6631 - acc: 0.4104 - val_loss: 1.5530 - val_acc: 0.4559\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 12s 232us/sample - loss: 1.6598 - acc: 0.4101 - val_loss: 1.5610 - val_acc: 0.4538\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 12s 233us/sample - loss: 1.6545 - acc: 0.4164 - val_loss: 1.5560 - val_acc: 0.4498\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 12s 234us/sample - loss: 1.6492 - acc: 0.4130 - val_loss: 1.5452 - val_acc: 0.4621\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 12s 232us/sample - loss: 1.6497 - acc: 0.4155 - val_loss: 1.5571 - val_acc: 0.4508\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 12s 233us/sample - loss: 1.6457 - acc: 0.4170 - val_loss: 1.5384 - val_acc: 0.4583\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 12s 233us/sample - loss: 1.6452 - acc: 0.4154 - val_loss: 1.5276 - val_acc: 0.4605\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 12s 232us/sample - loss: 1.6389 - acc: 0.4140 - val_loss: 1.5444 - val_acc: 0.4634\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 12s 233us/sample - loss: 1.6363 - acc: 0.4202 - val_loss: 1.5160 - val_acc: 0.4603\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 12s 245us/sample - loss: 1.6362 - acc: 0.4197 - val_loss: 1.5209 - val_acc: 0.4624\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 12s 233us/sample - loss: 1.6289 - acc: 0.4218 - val_loss: 1.5412 - val_acc: 0.4619\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 12s 235us/sample - loss: 1.6316 - acc: 0.4211 - val_loss: 1.5259 - val_acc: 0.4612\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 12s 232us/sample - loss: 1.6206 - acc: 0.4243 - val_loss: 1.5201 - val_acc: 0.4617\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 11s 227us/sample - loss: 1.6248 - acc: 0.4236 - val_loss: 1.5525 - val_acc: 0.4541\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 11s 226us/sample - loss: 1.6211 - acc: 0.4234 - val_loss: 1.5237 - val_acc: 0.4600\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 11s 229us/sample - loss: 1.6127 - acc: 0.4286 - val_loss: 1.5100 - val_acc: 0.4756\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 11s 226us/sample - loss: 1.6139 - acc: 0.4297 - val_loss: 1.5186 - val_acc: 0.4633\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 11s 226us/sample - loss: 1.6171 - acc: 0.4286 - val_loss: 1.5167 - val_acc: 0.4699\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 11s 225us/sample - loss: 1.6087 - acc: 0.4293 - val_loss: 1.5165 - val_acc: 0.4676\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 12s 247us/sample - loss: 1.6088 - acc: 0.4270 - val_loss: 1.5242 - val_acc: 0.4671\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 15s 293us/sample - loss: 1.6073 - acc: 0.4310 - val_loss: 1.5015 - val_acc: 0.4763\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 13s 261us/sample - loss: 1.6036 - acc: 0.4319 - val_loss: 1.5075 - val_acc: 0.4661\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 12s 236us/sample - loss: 1.6055 - acc: 0.4315 - val_loss: 1.5270 - val_acc: 0.4606\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 12s 233us/sample - loss: 1.6054 - acc: 0.4296 - val_loss: 1.5187 - val_acc: 0.4684\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 11s 229us/sample - loss: 1.6020 - acc: 0.4298 - val_loss: 1.5081 - val_acc: 0.4629\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 12s 230us/sample - loss: 1.5957 - acc: 0.4348 - val_loss: 1.5152 - val_acc: 0.4672\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 11s 229us/sample - loss: 1.5961 - acc: 0.4330 - val_loss: 1.5002 - val_acc: 0.4775\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 12s 230us/sample - loss: 1.5897 - acc: 0.4349 - val_loss: 1.5543 - val_acc: 0.4577\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 11s 229us/sample - loss: 1.5941 - acc: 0.4347 - val_loss: 1.5067 - val_acc: 0.4672\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 12s 236us/sample - loss: 1.5909 - acc: 0.4371 - val_loss: 1.4968 - val_acc: 0.4789\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 12s 234us/sample - loss: 1.5865 - acc: 0.4339 - val_loss: 1.5117 - val_acc: 0.4719\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 13s 257us/sample - loss: 1.5868 - acc: 0.4386 - val_loss: 1.4860 - val_acc: 0.4785\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 13s 252us/sample - loss: 1.5847 - acc: 0.4341 - val_loss: 1.4940 - val_acc: 0.4706\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 12s 235us/sample - loss: 1.5788 - acc: 0.4384 - val_loss: 1.5026 - val_acc: 0.4698\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 12s 240us/sample - loss: 1.5793 - acc: 0.4389 - val_loss: 1.5077 - val_acc: 0.4700\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5784 - acc: 0.4372 - val_loss: 1.5130 - val_acc: 0.4717\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5765 - acc: 0.4395 - val_loss: 1.5168 - val_acc: 0.4669\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5739 - acc: 0.4390 - val_loss: 1.5046 - val_acc: 0.4679\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 11s 221us/sample - loss: 1.5795 - acc: 0.4388 - val_loss: 1.5025 - val_acc: 0.4651\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 11s 223us/sample - loss: 1.5785 - acc: 0.4391 - val_loss: 1.4813 - val_acc: 0.4774\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 12s 232us/sample - loss: 1.5719 - acc: 0.4416 - val_loss: 1.4867 - val_acc: 0.4766\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 11s 221us/sample - loss: 1.5719 - acc: 0.4411 - val_loss: 1.5195 - val_acc: 0.4679\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5671 - acc: 0.4428 - val_loss: 1.5201 - val_acc: 0.4676\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 11s 221us/sample - loss: 1.5688 - acc: 0.4423 - val_loss: 1.4869 - val_acc: 0.4759\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5665 - acc: 0.4416 - val_loss: 1.5732 - val_acc: 0.4602\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 11s 221us/sample - loss: 1.5627 - acc: 0.4421 - val_loss: 1.4800 - val_acc: 0.4756\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5601 - acc: 0.4439 - val_loss: 1.4845 - val_acc: 0.4778\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5615 - acc: 0.4452 - val_loss: 1.5096 - val_acc: 0.4697\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 11s 224us/sample - loss: 1.5647 - acc: 0.4417 - val_loss: 1.4966 - val_acc: 0.4725\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 11s 224us/sample - loss: 1.5627 - acc: 0.4447 - val_loss: 1.4800 - val_acc: 0.4731\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 11s 226us/sample - loss: 1.5559 - acc: 0.4459 - val_loss: 1.5167 - val_acc: 0.4750\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 11s 225us/sample - loss: 1.5585 - acc: 0.4435 - val_loss: 1.5157 - val_acc: 0.4647\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 11s 224us/sample - loss: 1.5620 - acc: 0.4456 - val_loss: 1.5366 - val_acc: 0.4691\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5568 - acc: 0.4452 - val_loss: 1.4969 - val_acc: 0.4702\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5532 - acc: 0.4458 - val_loss: 1.4815 - val_acc: 0.4784\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5492 - acc: 0.4483 - val_loss: 1.5052 - val_acc: 0.4623\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 11s 222us/sample - loss: 1.5563 - acc: 0.4477 - val_loss: 1.4955 - val_acc: 0.4767\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 11s 223us/sample - loss: 1.5512 - acc: 0.4459 - val_loss: 1.5094 - val_acc: 0.4708\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 11s 228us/sample - loss: 1.5507 - acc: 0.4483 - val_loss: 1.5022 - val_acc: 0.4745\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 1.5475 - acc: 0.4474 - val_loss: 1.4733 - val_acc: 0.4813\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 1.5479 - acc: 0.4483 - val_loss: 1.4768 - val_acc: 0.4789\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 12s 232us/sample - loss: 1.5481 - acc: 0.4515 - val_loss: 1.4865 - val_acc: 0.4793\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 1.5449 - acc: 0.4491 - val_loss: 1.5022 - val_acc: 0.4754\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 1.5440 - acc: 0.4506 - val_loss: 1.4961 - val_acc: 0.4800\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 11s 221us/sample - loss: 1.5444 - acc: 0.4547 - val_loss: 1.4944 - val_acc: 0.4761\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 11s 221us/sample - loss: 1.5434 - acc: 0.4536 - val_loss: 1.5063 - val_acc: 0.4728\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 11s 220us/sample - loss: 1.5371 - acc: 0.4534 - val_loss: 1.4735 - val_acc: 0.4820\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 12s 245us/sample - loss: 1.5399 - acc: 0.4511 - val_loss: 1.4883 - val_acc: 0.4765\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 12s 249us/sample - loss: 1.5378 - acc: 0.4525 - val_loss: 1.5012 - val_acc: 0.4738\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 12s 235us/sample - loss: 1.5388 - acc: 0.4528 - val_loss: 1.4897 - val_acc: 0.4756\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 12s 231us/sample - loss: 1.5374 - acc: 0.4524 - val_loss: 1.4874 - val_acc: 0.4823\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 11s 230us/sample - loss: 1.5331 - acc: 0.4519 - val_loss: 1.4989 - val_acc: 0.4663\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 12s 237us/sample - loss: 1.5334 - acc: 0.4512 - val_loss: 1.4820 - val_acc: 0.4823\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 11s 230us/sample - loss: 1.5327 - acc: 0.4543 - val_loss: 1.5011 - val_acc: 0.4790\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 11s 229us/sample - loss: 1.5279 - acc: 0.4568 - val_loss: 1.4944 - val_acc: 0.4811\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 11s 229us/sample - loss: 1.5336 - acc: 0.4536 - val_loss: 1.4888 - val_acc: 0.4784\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 11s 229us/sample - loss: 1.5269 - acc: 0.4554 - val_loss: 1.5028 - val_acc: 0.4730\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 11s 228us/sample - loss: 1.5280 - acc: 0.4524 - val_loss: 1.4908 - val_acc: 0.4750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17f8e411688>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  307300    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  1010      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    multiple                  0         \n",
      "=================================================================\n",
      "Total params: 308,310\n",
      "Trainable params: 308,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_name = 'keras_cifar10_trained_model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'keras_cifar10_trained_model.h5')\n",
    "model2.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
